{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> **`Hard задача`. Классифицируем тексты** (задание степа 6.2.13)\n",
    "\n",
    "У вас есть датасет текстов постов из социальной сети. Вам нужно классифицировать их по 13 темам, к которым они относятся.\n",
    "\n",
    "**Достаем эмбеддинги при помощи языковых моделей**\n",
    "\n",
    "Очень часто в задачах, связанными с текстами, выстреливает подход с извлечением из текста эмбеддингов и последующего их использования в бустингах или линейных моделях для решения своей задачи.\n",
    "\n",
    "В рамках данного степа уже достали для каждого текста из датасета эмбеддинги при помощи больших языковых моделей из `HuggingFace`, а именно использовали `'sberbank-ai/ruBert-base'`, `'cointegrated/rubert-tiny2'`, `'DeepPavlov/rubert-base-cased-conversational'` и `'sentence-transformers/LaBSE'`.\n",
    "\n",
    "Так что теперь вы можете использовать их, чтобы составить свой невероятный ансамбль и порвать лидерборд.\n",
    "\n",
    "<center> <img src='../images/text_classes.png' width=\"900\" /> </center>\n",
    "\n",
    "**Задача:** Получите максимальное качество классификации. Метрика - balanced_accuracy_score, классы в тестовой выборке сбалансированны так же, как и в обучающей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cb_model_True_False_vicgalle_xlm-roberta-large-xnli-anli_512 0.0696\n",
    "cb_model_True_False_sentence-transformers_LaBSE_512 0.65\n",
    "cb_model_True_False_sberbank-ai_sbert_large_nlu_ru_512 0.56\n",
    "cb_model_True_False_sberbank-ai_sbert_large_mt_nlu_ru_512 0.572\n",
    "cb_model_True_False_sberbank-ai_ruRoberta-large_512 0.0748\n",
    "cb_model_True_False_sberbank-ai_ruBert-large_512 0.5148\n",
    "cb_model_True_False_sberbank-ai_ruBert-base_512 0.3468\n",
    "cb_model_True_False_DeepPavlov_rubert-base-cased-conversational_512 0.402\n",
    "cb_model_True_False_cointegrated_rubert-tiny2_2048 0.4768\n",
    "cb_model_True_False_cointegrated_LaBSE-en-ru_512 0.6596\n",
    "\n",
    "cb_model_True_False_4_llm 0.6512\n",
    "\n",
    "\n",
    "cb_model_False_True_vicgalle_xlm-roberta-large-xnli-anli_512 0.354\n",
    "cb_model_False_True_sentence-transformers_LaBSE_512 0.6588\n",
    "cb_model_False_True_sberbank-ai_sbert_large_nlu_ru_512 0.6224\n",
    "cb_model_False_True_sberbank-ai_sbert_large_mt_nlu_ru_512 0.5996\n",
    "cb_model_False_True_sberbank-ai_ruRoberta-large_512 0.5968\n",
    "cb_model_False_True_sberbank-ai_ruBert-large_512 0.6264\n",
    "cb_model_False_True_sberbank-ai_ruBert-base_512 0.6612\n",
    "cb_model_False_True_DeepPavlov_rubert-base-cased-conversational_512 0.5652\n",
    "cb_model_False_True_cointegrated_rubert-tiny2_2048 0.55\n",
    "cb_model_False_True_cointegrated_LaBSE-en-ru_512 0.6664\n",
    "\n",
    "cb_model_False_True_4_llm 0.6928"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cb_model_False_True_sberbank-ai_ruBert-base_512 0.6612\n",
    "\n",
    "cb_model_False_True_cointegrated_rubert-tiny2_2048 0.55\n",
    "cb_model_False_True_cointegrated_rubert-tiny2_512 0.5692\n",
    "\n",
    "cb_model_False_True_DeepPavlov_rubert-base-cased-conversational_512 0.5652\n",
    "\n",
    "cb_model_False_True_sentence-transformers_LaBSE_512 0.6588\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cb_model_False_True_cointegrated_LaBSE-en-ru_512 0.6664\n",
    "\n",
    "cb_model_False_True_4_llm_tiny2_2048 0.6928\n",
    "cb_model_False_True_4_llm_tiny2_512 0.6996\n",
    "\n",
    "\n",
    "cb_model_False_True_3_llm_without_pavlov 0.686\n",
    "\n",
    "\n",
    "\n",
    "cb_model_False_True_5_llm_tiny2_512 0.6932\n",
    "\n",
    "cb_model_False_True_5_without_llm_tiny2_512 0.6912"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextEmbeddings:\n",
    "    def __init__(self, add_cls_embeddings=True, add_mean_embeddings=False):\n",
    "        self.add_mean_embeddings = add_mean_embeddings\n",
    "        self.add_cls_embeddings = add_cls_embeddings\n",
    "        if add_cls_embeddings is False and add_mean_embeddings is False:\n",
    "            raise 'Error: you should select at least one type of embeddings to be computed'\n",
    "\n",
    "    def mean_pooling(self, hidden_state, attention_mask):\n",
    "        \"\"\"\n",
    "        Возвращает усредненный с учетом attention_mask hidden_state.\n",
    "        \"\"\"\n",
    "        token_embeddings = hidden_state.detach().cpu() \n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "        return sum_embeddings / attention_mask.sum()\n",
    "\n",
    "    def extract_embeddings(self, texts, model_name, max_len):\n",
    "        \"\"\"\n",
    "        Возвращает значения, посчитанные данной моделью - эмбеддинги для всех текстов из texts.\n",
    "        \"\"\"\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        model = AutoModel.from_pretrained(model_name).cuda()\n",
    "        text_features = []\n",
    "        for sentence in tqdm(texts):\n",
    "            encoded_input = tokenizer([sentence],\n",
    "                                      padding='max_length',\n",
    "                                      truncation=True,\n",
    "                                      max_length=max_len,\n",
    "                                      return_tensors='pt')\n",
    "            with torch.no_grad():\n",
    "                hidden_state, cls_head = model(input_ids=encoded_input['input_ids'].cuda(), return_dict=False)\n",
    "                sentence_embeddings = self.mean_pooling(hidden_state, encoded_input['attention_mask'])\n",
    "            \n",
    "            now_emb = []\n",
    "            if self.add_cls_embeddings:\n",
    "                now_emb.append(cls_head.detach().cpu().numpy().flatten())\n",
    "            \n",
    "            if self.add_mean_embeddings:\n",
    "                now_emb.append(sentence_embeddings.detach().cpu().numpy().flatten())\n",
    "            \n",
    "            text_features.append(np.concatenate(now_emb, axis=0))\n",
    "        return text_features\n",
    "\n",
    "    def add_many_embeddings(self, df, text_col, models):\n",
    "        \"\"\"\"\n",
    "        Добавляет в качестве признаков эмбеддинги для колонки text_col.\n",
    "        В качестве моделей и максимальных длин используются models.\n",
    "        \"\"\"\n",
    "        for model_name, max_len in models:\n",
    "            print(model_name)\n",
    "            text_features = self.extract_embeddings(df[text_col], model_name, max_len)\n",
    "            text_features_df = pd.DataFrame(text_features, columns = [f'{model_name}_{text_col}_feature_{i}' for i in range(len(text_features[0]))])\n",
    "            df = df.join(text_features_df)\n",
    "            df.to_csv('transformers_text_features.csv', index=False)\n",
    "            os.system('cp /content/transformers_text_features.csv /content/drive/MyDrive/datasets/transformers_text_features.csv')\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/text_classification_train.csv')\n",
    "test = pd.read_csv('../data/text_classification_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ruBert-base_text_feature - 768\n",
    "rubert-tiny2_text_feature - 312\n",
    "rubert-base-cased-conversational_text_feature - 768\n",
    "labse_text_feature - 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_False_True_4_llm_tiny2_512 = pd.read_csv('train_False_True_4_llm_tiny2_512.csv')\n",
    "train_False_True_4_llm_tiny2_2048 = pd.read_csv('train_False_True_4_llm_tiny2_2048.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ruBert-base_text_feature_0</th>\n",
       "      <th>ruBert-base_text_feature_1</th>\n",
       "      <th>ruBert-base_text_feature_2</th>\n",
       "      <th>ruBert-base_text_feature_3</th>\n",
       "      <th>ruBert-base_text_feature_4</th>\n",
       "      <th>ruBert-base_text_feature_5</th>\n",
       "      <th>ruBert-base_text_feature_6</th>\n",
       "      <th>ruBert-base_text_feature_7</th>\n",
       "      <th>ruBert-base_text_feature_8</th>\n",
       "      <th>ruBert-base_text_feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>labse_text_feature_758</th>\n",
       "      <th>labse_text_feature_759</th>\n",
       "      <th>labse_text_feature_760</th>\n",
       "      <th>labse_text_feature_761</th>\n",
       "      <th>labse_text_feature_762</th>\n",
       "      <th>labse_text_feature_763</th>\n",
       "      <th>labse_text_feature_764</th>\n",
       "      <th>labse_text_feature_765</th>\n",
       "      <th>labse_text_feature_766</th>\n",
       "      <th>labse_text_feature_767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.272156</td>\n",
       "      <td>0.155383</td>\n",
       "      <td>0.060285</td>\n",
       "      <td>0.363159</td>\n",
       "      <td>-0.140391</td>\n",
       "      <td>0.507753</td>\n",
       "      <td>-0.226326</td>\n",
       "      <td>0.431878</td>\n",
       "      <td>0.063127</td>\n",
       "      <td>-0.159407</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045795</td>\n",
       "      <td>-0.027475</td>\n",
       "      <td>0.030528</td>\n",
       "      <td>-0.052218</td>\n",
       "      <td>0.042459</td>\n",
       "      <td>-0.012714</td>\n",
       "      <td>-0.05537</td>\n",
       "      <td>-0.012433</td>\n",
       "      <td>-0.016283</td>\n",
       "      <td>-0.006994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 2616 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ruBert-base_text_feature_0  ruBert-base_text_feature_1  \\\n",
       "0                    0.272156                    0.155383   \n",
       "\n",
       "   ruBert-base_text_feature_2  ruBert-base_text_feature_3  \\\n",
       "0                    0.060285                    0.363159   \n",
       "\n",
       "   ruBert-base_text_feature_4  ruBert-base_text_feature_5  \\\n",
       "0                   -0.140391                    0.507753   \n",
       "\n",
       "   ruBert-base_text_feature_6  ruBert-base_text_feature_7  \\\n",
       "0                   -0.226326                    0.431878   \n",
       "\n",
       "   ruBert-base_text_feature_8  ruBert-base_text_feature_9  ...  \\\n",
       "0                    0.063127                   -0.159407  ...   \n",
       "\n",
       "   labse_text_feature_758  labse_text_feature_759  labse_text_feature_760  \\\n",
       "0               -0.045795               -0.027475                0.030528   \n",
       "\n",
       "   labse_text_feature_761  labse_text_feature_762  labse_text_feature_763  \\\n",
       "0               -0.052218                0.042459               -0.012714   \n",
       "\n",
       "   labse_text_feature_764  labse_text_feature_765  labse_text_feature_766  \\\n",
       "0                -0.05537               -0.012433               -0.016283   \n",
       "\n",
       "   labse_text_feature_767  \n",
       "0               -0.006994  \n",
       "\n",
       "[1 rows x 2616 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sberbank-ai/ruBert-base_text_feature_0</th>\n",
       "      <th>sberbank-ai/ruBert-base_text_feature_1</th>\n",
       "      <th>sberbank-ai/ruBert-base_text_feature_2</th>\n",
       "      <th>sberbank-ai/ruBert-base_text_feature_3</th>\n",
       "      <th>sberbank-ai/ruBert-base_text_feature_4</th>\n",
       "      <th>sberbank-ai/ruBert-base_text_feature_5</th>\n",
       "      <th>sberbank-ai/ruBert-base_text_feature_6</th>\n",
       "      <th>sberbank-ai/ruBert-base_text_feature_7</th>\n",
       "      <th>sberbank-ai/ruBert-base_text_feature_8</th>\n",
       "      <th>sberbank-ai/ruBert-base_text_feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_758</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_759</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_760</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_761</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_762</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_763</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_764</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_765</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_766</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.272157</td>\n",
       "      <td>0.155383</td>\n",
       "      <td>0.060286</td>\n",
       "      <td>0.363159</td>\n",
       "      <td>-0.140392</td>\n",
       "      <td>0.507753</td>\n",
       "      <td>-0.226326</td>\n",
       "      <td>0.431878</td>\n",
       "      <td>0.063128</td>\n",
       "      <td>-0.159407</td>\n",
       "      <td>...</td>\n",
       "      <td>0.297108</td>\n",
       "      <td>-0.040586</td>\n",
       "      <td>0.602947</td>\n",
       "      <td>-0.2219</td>\n",
       "      <td>1.02662</td>\n",
       "      <td>0.107726</td>\n",
       "      <td>-0.359772</td>\n",
       "      <td>0.015022</td>\n",
       "      <td>-0.514056</td>\n",
       "      <td>-0.497934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 2616 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sberbank-ai/ruBert-base_text_feature_0  \\\n",
       "0                                0.272157   \n",
       "\n",
       "   sberbank-ai/ruBert-base_text_feature_1  \\\n",
       "0                                0.155383   \n",
       "\n",
       "   sberbank-ai/ruBert-base_text_feature_2  \\\n",
       "0                                0.060286   \n",
       "\n",
       "   sberbank-ai/ruBert-base_text_feature_3  \\\n",
       "0                                0.363159   \n",
       "\n",
       "   sberbank-ai/ruBert-base_text_feature_4  \\\n",
       "0                               -0.140392   \n",
       "\n",
       "   sberbank-ai/ruBert-base_text_feature_5  \\\n",
       "0                                0.507753   \n",
       "\n",
       "   sberbank-ai/ruBert-base_text_feature_6  \\\n",
       "0                               -0.226326   \n",
       "\n",
       "   sberbank-ai/ruBert-base_text_feature_7  \\\n",
       "0                                0.431878   \n",
       "\n",
       "   sberbank-ai/ruBert-base_text_feature_8  \\\n",
       "0                                0.063128   \n",
       "\n",
       "   sberbank-ai/ruBert-base_text_feature_9  ...  \\\n",
       "0                               -0.159407  ...   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_758  \\\n",
       "0                                      0.297108   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_759  \\\n",
       "0                                     -0.040586   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_760  \\\n",
       "0                                      0.602947   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_761  \\\n",
       "0                                       -0.2219   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_762  \\\n",
       "0                                       1.02662   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_763  \\\n",
       "0                                      0.107726   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_764  \\\n",
       "0                                     -0.359772   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_765  \\\n",
       "0                                      0.015022   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_766  \\\n",
       "0                                     -0.514056   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_767  \n",
       "0                                     -0.497934  \n",
       "\n",
       "[1 rows x 2616 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sberbank-ai/ruBert-base_text_feature_0</th>\n",
       "      <th>sberbank-ai/ruBert-base_text_feature_1</th>\n",
       "      <th>sberbank-ai/ruBert-base_text_feature_2</th>\n",
       "      <th>sberbank-ai/ruBert-base_text_feature_3</th>\n",
       "      <th>sberbank-ai/ruBert-base_text_feature_4</th>\n",
       "      <th>sberbank-ai/ruBert-base_text_feature_5</th>\n",
       "      <th>sberbank-ai/ruBert-base_text_feature_6</th>\n",
       "      <th>sberbank-ai/ruBert-base_text_feature_7</th>\n",
       "      <th>sberbank-ai/ruBert-base_text_feature_8</th>\n",
       "      <th>sberbank-ai/ruBert-base_text_feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_758</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_759</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_760</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_761</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_762</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_763</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_764</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_765</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_766</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.272157</td>\n",
       "      <td>0.155383</td>\n",
       "      <td>0.060286</td>\n",
       "      <td>0.363159</td>\n",
       "      <td>-0.140392</td>\n",
       "      <td>0.507753</td>\n",
       "      <td>-0.226326</td>\n",
       "      <td>0.431878</td>\n",
       "      <td>0.063128</td>\n",
       "      <td>-0.159407</td>\n",
       "      <td>...</td>\n",
       "      <td>0.297108</td>\n",
       "      <td>-0.040586</td>\n",
       "      <td>0.602947</td>\n",
       "      <td>-0.2219</td>\n",
       "      <td>1.02662</td>\n",
       "      <td>0.107726</td>\n",
       "      <td>-0.359772</td>\n",
       "      <td>0.015022</td>\n",
       "      <td>-0.514056</td>\n",
       "      <td>-0.497934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 2616 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sberbank-ai/ruBert-base_text_feature_0  \\\n",
       "0                                0.272157   \n",
       "\n",
       "   sberbank-ai/ruBert-base_text_feature_1  \\\n",
       "0                                0.155383   \n",
       "\n",
       "   sberbank-ai/ruBert-base_text_feature_2  \\\n",
       "0                                0.060286   \n",
       "\n",
       "   sberbank-ai/ruBert-base_text_feature_3  \\\n",
       "0                                0.363159   \n",
       "\n",
       "   sberbank-ai/ruBert-base_text_feature_4  \\\n",
       "0                               -0.140392   \n",
       "\n",
       "   sberbank-ai/ruBert-base_text_feature_5  \\\n",
       "0                                0.507753   \n",
       "\n",
       "   sberbank-ai/ruBert-base_text_feature_6  \\\n",
       "0                               -0.226326   \n",
       "\n",
       "   sberbank-ai/ruBert-base_text_feature_7  \\\n",
       "0                                0.431878   \n",
       "\n",
       "   sberbank-ai/ruBert-base_text_feature_8  \\\n",
       "0                                0.063128   \n",
       "\n",
       "   sberbank-ai/ruBert-base_text_feature_9  ...  \\\n",
       "0                               -0.159407  ...   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_758  \\\n",
       "0                                      0.297108   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_759  \\\n",
       "0                                     -0.040586   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_760  \\\n",
       "0                                      0.602947   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_761  \\\n",
       "0                                       -0.2219   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_762  \\\n",
       "0                                       1.02662   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_763  \\\n",
       "0                                      0.107726   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_764  \\\n",
       "0                                     -0.359772   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_765  \\\n",
       "0                                      0.015022   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_766  \\\n",
       "0                                     -0.514056   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_767  \n",
       "0                                     -0.497934  \n",
       "\n",
       "[1 rows x 2616 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_full.iloc[:1, 2:])\n",
    "display(train_False_True_4_llm_tiny2_512.iloc[:1, 2:])\n",
    "display(train_False_True_4_llm_tiny2_2048.iloc[:1, 2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rubert-tiny2_text_feature_0</th>\n",
       "      <th>rubert-tiny2_text_feature_1</th>\n",
       "      <th>rubert-tiny2_text_feature_2</th>\n",
       "      <th>rubert-tiny2_text_feature_3</th>\n",
       "      <th>rubert-tiny2_text_feature_4</th>\n",
       "      <th>rubert-tiny2_text_feature_5</th>\n",
       "      <th>rubert-tiny2_text_feature_6</th>\n",
       "      <th>rubert-tiny2_text_feature_7</th>\n",
       "      <th>rubert-tiny2_text_feature_8</th>\n",
       "      <th>rubert-tiny2_text_feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>labse_text_feature_758</th>\n",
       "      <th>labse_text_feature_759</th>\n",
       "      <th>labse_text_feature_760</th>\n",
       "      <th>labse_text_feature_761</th>\n",
       "      <th>labse_text_feature_762</th>\n",
       "      <th>labse_text_feature_763</th>\n",
       "      <th>labse_text_feature_764</th>\n",
       "      <th>labse_text_feature_765</th>\n",
       "      <th>labse_text_feature_766</th>\n",
       "      <th>labse_text_feature_767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.27044</td>\n",
       "      <td>0.125625</td>\n",
       "      <td>0.274958</td>\n",
       "      <td>-1.458633</td>\n",
       "      <td>-0.325684</td>\n",
       "      <td>0.209481</td>\n",
       "      <td>-0.538193</td>\n",
       "      <td>-0.294977</td>\n",
       "      <td>-0.113118</td>\n",
       "      <td>-0.137835</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045795</td>\n",
       "      <td>-0.027475</td>\n",
       "      <td>0.030528</td>\n",
       "      <td>-0.052218</td>\n",
       "      <td>0.042459</td>\n",
       "      <td>-0.012714</td>\n",
       "      <td>-0.05537</td>\n",
       "      <td>-0.012433</td>\n",
       "      <td>-0.016283</td>\n",
       "      <td>-0.006994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 1848 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rubert-tiny2_text_feature_0  rubert-tiny2_text_feature_1  \\\n",
       "0                     -0.27044                     0.125625   \n",
       "\n",
       "   rubert-tiny2_text_feature_2  rubert-tiny2_text_feature_3  \\\n",
       "0                     0.274958                    -1.458633   \n",
       "\n",
       "   rubert-tiny2_text_feature_4  rubert-tiny2_text_feature_5  \\\n",
       "0                    -0.325684                     0.209481   \n",
       "\n",
       "   rubert-tiny2_text_feature_6  rubert-tiny2_text_feature_7  \\\n",
       "0                    -0.538193                    -0.294977   \n",
       "\n",
       "   rubert-tiny2_text_feature_8  rubert-tiny2_text_feature_9  ...  \\\n",
       "0                    -0.113118                    -0.137835  ...   \n",
       "\n",
       "   labse_text_feature_758  labse_text_feature_759  labse_text_feature_760  \\\n",
       "0               -0.045795               -0.027475                0.030528   \n",
       "\n",
       "   labse_text_feature_761  labse_text_feature_762  labse_text_feature_763  \\\n",
       "0               -0.052218                0.042459               -0.012714   \n",
       "\n",
       "   labse_text_feature_764  labse_text_feature_765  labse_text_feature_766  \\\n",
       "0                -0.05537               -0.012433               -0.016283   \n",
       "\n",
       "   labse_text_feature_767  \n",
       "0               -0.006994  \n",
       "\n",
       "[1 rows x 1848 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cointegrated/rubert-tiny2_text_feature_0</th>\n",
       "      <th>cointegrated/rubert-tiny2_text_feature_1</th>\n",
       "      <th>cointegrated/rubert-tiny2_text_feature_2</th>\n",
       "      <th>cointegrated/rubert-tiny2_text_feature_3</th>\n",
       "      <th>cointegrated/rubert-tiny2_text_feature_4</th>\n",
       "      <th>cointegrated/rubert-tiny2_text_feature_5</th>\n",
       "      <th>cointegrated/rubert-tiny2_text_feature_6</th>\n",
       "      <th>cointegrated/rubert-tiny2_text_feature_7</th>\n",
       "      <th>cointegrated/rubert-tiny2_text_feature_8</th>\n",
       "      <th>cointegrated/rubert-tiny2_text_feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_758</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_759</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_760</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_761</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_762</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_763</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_764</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_765</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_766</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.123901</td>\n",
       "      <td>0.132128</td>\n",
       "      <td>0.3476</td>\n",
       "      <td>-1.503766</td>\n",
       "      <td>-0.280612</td>\n",
       "      <td>0.191466</td>\n",
       "      <td>-0.545496</td>\n",
       "      <td>-0.252253</td>\n",
       "      <td>-0.174542</td>\n",
       "      <td>-0.213611</td>\n",
       "      <td>...</td>\n",
       "      <td>0.297108</td>\n",
       "      <td>-0.040586</td>\n",
       "      <td>0.602947</td>\n",
       "      <td>-0.2219</td>\n",
       "      <td>1.02662</td>\n",
       "      <td>0.107726</td>\n",
       "      <td>-0.359772</td>\n",
       "      <td>0.015022</td>\n",
       "      <td>-0.514056</td>\n",
       "      <td>-0.497934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 1848 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cointegrated/rubert-tiny2_text_feature_0  \\\n",
       "0                                 -0.123901   \n",
       "\n",
       "   cointegrated/rubert-tiny2_text_feature_1  \\\n",
       "0                                  0.132128   \n",
       "\n",
       "   cointegrated/rubert-tiny2_text_feature_2  \\\n",
       "0                                    0.3476   \n",
       "\n",
       "   cointegrated/rubert-tiny2_text_feature_3  \\\n",
       "0                                 -1.503766   \n",
       "\n",
       "   cointegrated/rubert-tiny2_text_feature_4  \\\n",
       "0                                 -0.280612   \n",
       "\n",
       "   cointegrated/rubert-tiny2_text_feature_5  \\\n",
       "0                                  0.191466   \n",
       "\n",
       "   cointegrated/rubert-tiny2_text_feature_6  \\\n",
       "0                                 -0.545496   \n",
       "\n",
       "   cointegrated/rubert-tiny2_text_feature_7  \\\n",
       "0                                 -0.252253   \n",
       "\n",
       "   cointegrated/rubert-tiny2_text_feature_8  \\\n",
       "0                                 -0.174542   \n",
       "\n",
       "   cointegrated/rubert-tiny2_text_feature_9  ...  \\\n",
       "0                                 -0.213611  ...   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_758  \\\n",
       "0                                      0.297108   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_759  \\\n",
       "0                                     -0.040586   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_760  \\\n",
       "0                                      0.602947   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_761  \\\n",
       "0                                       -0.2219   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_762  \\\n",
       "0                                       1.02662   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_763  \\\n",
       "0                                      0.107726   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_764  \\\n",
       "0                                     -0.359772   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_765  \\\n",
       "0                                      0.015022   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_766  \\\n",
       "0                                     -0.514056   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_767  \n",
       "0                                     -0.497934  \n",
       "\n",
       "[1 rows x 1848 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cointegrated/rubert-tiny2_text_feature_0</th>\n",
       "      <th>cointegrated/rubert-tiny2_text_feature_1</th>\n",
       "      <th>cointegrated/rubert-tiny2_text_feature_2</th>\n",
       "      <th>cointegrated/rubert-tiny2_text_feature_3</th>\n",
       "      <th>cointegrated/rubert-tiny2_text_feature_4</th>\n",
       "      <th>cointegrated/rubert-tiny2_text_feature_5</th>\n",
       "      <th>cointegrated/rubert-tiny2_text_feature_6</th>\n",
       "      <th>cointegrated/rubert-tiny2_text_feature_7</th>\n",
       "      <th>cointegrated/rubert-tiny2_text_feature_8</th>\n",
       "      <th>cointegrated/rubert-tiny2_text_feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_758</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_759</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_760</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_761</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_762</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_763</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_764</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_765</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_766</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.27044</td>\n",
       "      <td>0.125625</td>\n",
       "      <td>0.274958</td>\n",
       "      <td>-1.458632</td>\n",
       "      <td>-0.325684</td>\n",
       "      <td>0.209481</td>\n",
       "      <td>-0.538193</td>\n",
       "      <td>-0.294977</td>\n",
       "      <td>-0.113118</td>\n",
       "      <td>-0.137835</td>\n",
       "      <td>...</td>\n",
       "      <td>0.297108</td>\n",
       "      <td>-0.040586</td>\n",
       "      <td>0.602947</td>\n",
       "      <td>-0.2219</td>\n",
       "      <td>1.02662</td>\n",
       "      <td>0.107726</td>\n",
       "      <td>-0.359772</td>\n",
       "      <td>0.015022</td>\n",
       "      <td>-0.514056</td>\n",
       "      <td>-0.497934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 1848 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cointegrated/rubert-tiny2_text_feature_0  \\\n",
       "0                                  -0.27044   \n",
       "\n",
       "   cointegrated/rubert-tiny2_text_feature_1  \\\n",
       "0                                  0.125625   \n",
       "\n",
       "   cointegrated/rubert-tiny2_text_feature_2  \\\n",
       "0                                  0.274958   \n",
       "\n",
       "   cointegrated/rubert-tiny2_text_feature_3  \\\n",
       "0                                 -1.458632   \n",
       "\n",
       "   cointegrated/rubert-tiny2_text_feature_4  \\\n",
       "0                                 -0.325684   \n",
       "\n",
       "   cointegrated/rubert-tiny2_text_feature_5  \\\n",
       "0                                  0.209481   \n",
       "\n",
       "   cointegrated/rubert-tiny2_text_feature_6  \\\n",
       "0                                 -0.538193   \n",
       "\n",
       "   cointegrated/rubert-tiny2_text_feature_7  \\\n",
       "0                                 -0.294977   \n",
       "\n",
       "   cointegrated/rubert-tiny2_text_feature_8  \\\n",
       "0                                 -0.113118   \n",
       "\n",
       "   cointegrated/rubert-tiny2_text_feature_9  ...  \\\n",
       "0                                 -0.137835  ...   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_758  \\\n",
       "0                                      0.297108   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_759  \\\n",
       "0                                     -0.040586   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_760  \\\n",
       "0                                      0.602947   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_761  \\\n",
       "0                                       -0.2219   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_762  \\\n",
       "0                                       1.02662   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_763  \\\n",
       "0                                      0.107726   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_764  \\\n",
       "0                                     -0.359772   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_765  \\\n",
       "0                                      0.015022   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_766  \\\n",
       "0                                     -0.514056   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_767  \n",
       "0                                     -0.497934  \n",
       "\n",
       "[1 rows x 1848 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_full.iloc[:1, 770:])\n",
    "display(train_False_True_4_llm_tiny2_512.iloc[:1, 770:])\n",
    "display(train_False_True_4_llm_tiny2_2048.iloc[:1, 770:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rubert-base-cased-conversational_text_feature_0</th>\n",
       "      <th>rubert-base-cased-conversational_text_feature_1</th>\n",
       "      <th>rubert-base-cased-conversational_text_feature_2</th>\n",
       "      <th>rubert-base-cased-conversational_text_feature_3</th>\n",
       "      <th>rubert-base-cased-conversational_text_feature_4</th>\n",
       "      <th>rubert-base-cased-conversational_text_feature_5</th>\n",
       "      <th>rubert-base-cased-conversational_text_feature_6</th>\n",
       "      <th>rubert-base-cased-conversational_text_feature_7</th>\n",
       "      <th>rubert-base-cased-conversational_text_feature_8</th>\n",
       "      <th>rubert-base-cased-conversational_text_feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>labse_text_feature_758</th>\n",
       "      <th>labse_text_feature_759</th>\n",
       "      <th>labse_text_feature_760</th>\n",
       "      <th>labse_text_feature_761</th>\n",
       "      <th>labse_text_feature_762</th>\n",
       "      <th>labse_text_feature_763</th>\n",
       "      <th>labse_text_feature_764</th>\n",
       "      <th>labse_text_feature_765</th>\n",
       "      <th>labse_text_feature_766</th>\n",
       "      <th>labse_text_feature_767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.618955</td>\n",
       "      <td>-0.219039</td>\n",
       "      <td>-0.295544</td>\n",
       "      <td>-0.043835</td>\n",
       "      <td>0.187447</td>\n",
       "      <td>0.339212</td>\n",
       "      <td>0.297977</td>\n",
       "      <td>0.204835</td>\n",
       "      <td>0.019111</td>\n",
       "      <td>0.424508</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045795</td>\n",
       "      <td>-0.027475</td>\n",
       "      <td>0.030528</td>\n",
       "      <td>-0.052218</td>\n",
       "      <td>0.042459</td>\n",
       "      <td>-0.012714</td>\n",
       "      <td>-0.05537</td>\n",
       "      <td>-0.012433</td>\n",
       "      <td>-0.016283</td>\n",
       "      <td>-0.006994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 1536 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rubert-base-cased-conversational_text_feature_0  \\\n",
       "0                                        -0.618955   \n",
       "\n",
       "   rubert-base-cased-conversational_text_feature_1  \\\n",
       "0                                        -0.219039   \n",
       "\n",
       "   rubert-base-cased-conversational_text_feature_2  \\\n",
       "0                                        -0.295544   \n",
       "\n",
       "   rubert-base-cased-conversational_text_feature_3  \\\n",
       "0                                        -0.043835   \n",
       "\n",
       "   rubert-base-cased-conversational_text_feature_4  \\\n",
       "0                                         0.187447   \n",
       "\n",
       "   rubert-base-cased-conversational_text_feature_5  \\\n",
       "0                                         0.339212   \n",
       "\n",
       "   rubert-base-cased-conversational_text_feature_6  \\\n",
       "0                                         0.297977   \n",
       "\n",
       "   rubert-base-cased-conversational_text_feature_7  \\\n",
       "0                                         0.204835   \n",
       "\n",
       "   rubert-base-cased-conversational_text_feature_8  \\\n",
       "0                                         0.019111   \n",
       "\n",
       "   rubert-base-cased-conversational_text_feature_9  ...  \\\n",
       "0                                         0.424508  ...   \n",
       "\n",
       "   labse_text_feature_758  labse_text_feature_759  labse_text_feature_760  \\\n",
       "0               -0.045795               -0.027475                0.030528   \n",
       "\n",
       "   labse_text_feature_761  labse_text_feature_762  labse_text_feature_763  \\\n",
       "0               -0.052218                0.042459               -0.012714   \n",
       "\n",
       "   labse_text_feature_764  labse_text_feature_765  labse_text_feature_766  \\\n",
       "0                -0.05537               -0.012433               -0.016283   \n",
       "\n",
       "   labse_text_feature_767  \n",
       "0               -0.006994  \n",
       "\n",
       "[1 rows x 1536 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DeepPavlov/rubert-base-cased-conversational_text_feature_0</th>\n",
       "      <th>DeepPavlov/rubert-base-cased-conversational_text_feature_1</th>\n",
       "      <th>DeepPavlov/rubert-base-cased-conversational_text_feature_2</th>\n",
       "      <th>DeepPavlov/rubert-base-cased-conversational_text_feature_3</th>\n",
       "      <th>DeepPavlov/rubert-base-cased-conversational_text_feature_4</th>\n",
       "      <th>DeepPavlov/rubert-base-cased-conversational_text_feature_5</th>\n",
       "      <th>DeepPavlov/rubert-base-cased-conversational_text_feature_6</th>\n",
       "      <th>DeepPavlov/rubert-base-cased-conversational_text_feature_7</th>\n",
       "      <th>DeepPavlov/rubert-base-cased-conversational_text_feature_8</th>\n",
       "      <th>DeepPavlov/rubert-base-cased-conversational_text_feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_758</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_759</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_760</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_761</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_762</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_763</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_764</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_765</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_766</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.618956</td>\n",
       "      <td>-0.219038</td>\n",
       "      <td>-0.295542</td>\n",
       "      <td>-0.043835</td>\n",
       "      <td>0.187446</td>\n",
       "      <td>0.339212</td>\n",
       "      <td>0.297976</td>\n",
       "      <td>0.204837</td>\n",
       "      <td>0.01911</td>\n",
       "      <td>0.424507</td>\n",
       "      <td>...</td>\n",
       "      <td>0.297108</td>\n",
       "      <td>-0.040586</td>\n",
       "      <td>0.602947</td>\n",
       "      <td>-0.2219</td>\n",
       "      <td>1.02662</td>\n",
       "      <td>0.107726</td>\n",
       "      <td>-0.359772</td>\n",
       "      <td>0.015022</td>\n",
       "      <td>-0.514056</td>\n",
       "      <td>-0.497934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 1536 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   DeepPavlov/rubert-base-cased-conversational_text_feature_0  \\\n",
       "0                                          -0.618956            \n",
       "\n",
       "   DeepPavlov/rubert-base-cased-conversational_text_feature_1  \\\n",
       "0                                          -0.219038            \n",
       "\n",
       "   DeepPavlov/rubert-base-cased-conversational_text_feature_2  \\\n",
       "0                                          -0.295542            \n",
       "\n",
       "   DeepPavlov/rubert-base-cased-conversational_text_feature_3  \\\n",
       "0                                          -0.043835            \n",
       "\n",
       "   DeepPavlov/rubert-base-cased-conversational_text_feature_4  \\\n",
       "0                                           0.187446            \n",
       "\n",
       "   DeepPavlov/rubert-base-cased-conversational_text_feature_5  \\\n",
       "0                                           0.339212            \n",
       "\n",
       "   DeepPavlov/rubert-base-cased-conversational_text_feature_6  \\\n",
       "0                                           0.297976            \n",
       "\n",
       "   DeepPavlov/rubert-base-cased-conversational_text_feature_7  \\\n",
       "0                                           0.204837            \n",
       "\n",
       "   DeepPavlov/rubert-base-cased-conversational_text_feature_8  \\\n",
       "0                                            0.01911            \n",
       "\n",
       "   DeepPavlov/rubert-base-cased-conversational_text_feature_9  ...  \\\n",
       "0                                           0.424507           ...   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_758  \\\n",
       "0                                      0.297108   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_759  \\\n",
       "0                                     -0.040586   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_760  \\\n",
       "0                                      0.602947   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_761  \\\n",
       "0                                       -0.2219   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_762  \\\n",
       "0                                       1.02662   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_763  \\\n",
       "0                                      0.107726   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_764  \\\n",
       "0                                     -0.359772   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_765  \\\n",
       "0                                      0.015022   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_766  \\\n",
       "0                                     -0.514056   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_767  \n",
       "0                                     -0.497934  \n",
       "\n",
       "[1 rows x 1536 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DeepPavlov/rubert-base-cased-conversational_text_feature_0</th>\n",
       "      <th>DeepPavlov/rubert-base-cased-conversational_text_feature_1</th>\n",
       "      <th>DeepPavlov/rubert-base-cased-conversational_text_feature_2</th>\n",
       "      <th>DeepPavlov/rubert-base-cased-conversational_text_feature_3</th>\n",
       "      <th>DeepPavlov/rubert-base-cased-conversational_text_feature_4</th>\n",
       "      <th>DeepPavlov/rubert-base-cased-conversational_text_feature_5</th>\n",
       "      <th>DeepPavlov/rubert-base-cased-conversational_text_feature_6</th>\n",
       "      <th>DeepPavlov/rubert-base-cased-conversational_text_feature_7</th>\n",
       "      <th>DeepPavlov/rubert-base-cased-conversational_text_feature_8</th>\n",
       "      <th>DeepPavlov/rubert-base-cased-conversational_text_feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_758</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_759</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_760</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_761</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_762</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_763</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_764</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_765</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_766</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.618956</td>\n",
       "      <td>-0.219038</td>\n",
       "      <td>-0.295542</td>\n",
       "      <td>-0.043835</td>\n",
       "      <td>0.187446</td>\n",
       "      <td>0.339212</td>\n",
       "      <td>0.297976</td>\n",
       "      <td>0.204837</td>\n",
       "      <td>0.01911</td>\n",
       "      <td>0.424507</td>\n",
       "      <td>...</td>\n",
       "      <td>0.297108</td>\n",
       "      <td>-0.040586</td>\n",
       "      <td>0.602947</td>\n",
       "      <td>-0.2219</td>\n",
       "      <td>1.02662</td>\n",
       "      <td>0.107726</td>\n",
       "      <td>-0.359772</td>\n",
       "      <td>0.015022</td>\n",
       "      <td>-0.514056</td>\n",
       "      <td>-0.497934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 1536 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   DeepPavlov/rubert-base-cased-conversational_text_feature_0  \\\n",
       "0                                          -0.618956            \n",
       "\n",
       "   DeepPavlov/rubert-base-cased-conversational_text_feature_1  \\\n",
       "0                                          -0.219038            \n",
       "\n",
       "   DeepPavlov/rubert-base-cased-conversational_text_feature_2  \\\n",
       "0                                          -0.295542            \n",
       "\n",
       "   DeepPavlov/rubert-base-cased-conversational_text_feature_3  \\\n",
       "0                                          -0.043835            \n",
       "\n",
       "   DeepPavlov/rubert-base-cased-conversational_text_feature_4  \\\n",
       "0                                           0.187446            \n",
       "\n",
       "   DeepPavlov/rubert-base-cased-conversational_text_feature_5  \\\n",
       "0                                           0.339212            \n",
       "\n",
       "   DeepPavlov/rubert-base-cased-conversational_text_feature_6  \\\n",
       "0                                           0.297976            \n",
       "\n",
       "   DeepPavlov/rubert-base-cased-conversational_text_feature_7  \\\n",
       "0                                           0.204837            \n",
       "\n",
       "   DeepPavlov/rubert-base-cased-conversational_text_feature_8  \\\n",
       "0                                            0.01911            \n",
       "\n",
       "   DeepPavlov/rubert-base-cased-conversational_text_feature_9  ...  \\\n",
       "0                                           0.424507           ...   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_758  \\\n",
       "0                                      0.297108   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_759  \\\n",
       "0                                     -0.040586   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_760  \\\n",
       "0                                      0.602947   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_761  \\\n",
       "0                                       -0.2219   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_762  \\\n",
       "0                                       1.02662   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_763  \\\n",
       "0                                      0.107726   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_764  \\\n",
       "0                                     -0.359772   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_765  \\\n",
       "0                                      0.015022   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_766  \\\n",
       "0                                     -0.514056   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_767  \n",
       "0                                     -0.497934  \n",
       "\n",
       "[1 rows x 1536 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_full.iloc[:1, 1082:])\n",
    "display(train_False_True_4_llm_tiny2_512.iloc[:1, 1082:])\n",
    "display(train_False_True_4_llm_tiny2_2048.iloc[:1, 1082:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labse_text_feature_0</th>\n",
       "      <th>labse_text_feature_1</th>\n",
       "      <th>labse_text_feature_2</th>\n",
       "      <th>labse_text_feature_3</th>\n",
       "      <th>labse_text_feature_4</th>\n",
       "      <th>labse_text_feature_5</th>\n",
       "      <th>labse_text_feature_6</th>\n",
       "      <th>labse_text_feature_7</th>\n",
       "      <th>labse_text_feature_8</th>\n",
       "      <th>labse_text_feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>labse_text_feature_758</th>\n",
       "      <th>labse_text_feature_759</th>\n",
       "      <th>labse_text_feature_760</th>\n",
       "      <th>labse_text_feature_761</th>\n",
       "      <th>labse_text_feature_762</th>\n",
       "      <th>labse_text_feature_763</th>\n",
       "      <th>labse_text_feature_764</th>\n",
       "      <th>labse_text_feature_765</th>\n",
       "      <th>labse_text_feature_766</th>\n",
       "      <th>labse_text_feature_767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.033953</td>\n",
       "      <td>-0.057514</td>\n",
       "      <td>-0.032344</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>-0.064609</td>\n",
       "      <td>-0.05585</td>\n",
       "      <td>-0.016916</td>\n",
       "      <td>-0.001691</td>\n",
       "      <td>-0.010337</td>\n",
       "      <td>-0.018989</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045795</td>\n",
       "      <td>-0.027475</td>\n",
       "      <td>0.030528</td>\n",
       "      <td>-0.052218</td>\n",
       "      <td>0.042459</td>\n",
       "      <td>-0.012714</td>\n",
       "      <td>-0.05537</td>\n",
       "      <td>-0.012433</td>\n",
       "      <td>-0.016283</td>\n",
       "      <td>-0.006994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   labse_text_feature_0  labse_text_feature_1  labse_text_feature_2  \\\n",
       "0             -0.033953             -0.057514             -0.032344   \n",
       "\n",
       "   labse_text_feature_3  labse_text_feature_4  labse_text_feature_5  \\\n",
       "0              0.007962             -0.064609              -0.05585   \n",
       "\n",
       "   labse_text_feature_6  labse_text_feature_7  labse_text_feature_8  \\\n",
       "0             -0.016916             -0.001691             -0.010337   \n",
       "\n",
       "   labse_text_feature_9  ...  labse_text_feature_758  labse_text_feature_759  \\\n",
       "0             -0.018989  ...               -0.045795               -0.027475   \n",
       "\n",
       "   labse_text_feature_760  labse_text_feature_761  labse_text_feature_762  \\\n",
       "0                0.030528               -0.052218                0.042459   \n",
       "\n",
       "   labse_text_feature_763  labse_text_feature_764  labse_text_feature_765  \\\n",
       "0               -0.012714                -0.05537               -0.012433   \n",
       "\n",
       "   labse_text_feature_766  labse_text_feature_767  \n",
       "0               -0.016283               -0.006994  \n",
       "\n",
       "[1 rows x 768 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_0</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_1</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_2</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_3</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_4</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_5</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_6</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_7</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_8</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_758</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_759</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_760</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_761</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_762</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_763</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_764</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_765</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_766</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.857106</td>\n",
       "      <td>-0.215657</td>\n",
       "      <td>1.067143</td>\n",
       "      <td>0.311904</td>\n",
       "      <td>-0.330101</td>\n",
       "      <td>0.720545</td>\n",
       "      <td>-0.263803</td>\n",
       "      <td>0.03688</td>\n",
       "      <td>-0.350564</td>\n",
       "      <td>-0.579427</td>\n",
       "      <td>...</td>\n",
       "      <td>0.297108</td>\n",
       "      <td>-0.040586</td>\n",
       "      <td>0.602947</td>\n",
       "      <td>-0.2219</td>\n",
       "      <td>1.02662</td>\n",
       "      <td>0.107726</td>\n",
       "      <td>-0.359772</td>\n",
       "      <td>0.015022</td>\n",
       "      <td>-0.514056</td>\n",
       "      <td>-0.497934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence-transformers/LaBSE_text_feature_0  \\\n",
       "0                                    0.857106   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_1  \\\n",
       "0                                   -0.215657   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_2  \\\n",
       "0                                    1.067143   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_3  \\\n",
       "0                                    0.311904   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_4  \\\n",
       "0                                   -0.330101   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_5  \\\n",
       "0                                    0.720545   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_6  \\\n",
       "0                                   -0.263803   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_7  \\\n",
       "0                                     0.03688   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_8  \\\n",
       "0                                   -0.350564   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_9  ...  \\\n",
       "0                                   -0.579427  ...   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_758  \\\n",
       "0                                      0.297108   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_759  \\\n",
       "0                                     -0.040586   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_760  \\\n",
       "0                                      0.602947   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_761  \\\n",
       "0                                       -0.2219   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_762  \\\n",
       "0                                       1.02662   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_763  \\\n",
       "0                                      0.107726   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_764  \\\n",
       "0                                     -0.359772   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_765  \\\n",
       "0                                      0.015022   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_766  \\\n",
       "0                                     -0.514056   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_767  \n",
       "0                                     -0.497934  \n",
       "\n",
       "[1 rows x 768 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_0</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_1</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_2</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_3</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_4</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_5</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_6</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_7</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_8</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_758</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_759</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_760</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_761</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_762</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_763</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_764</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_765</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_766</th>\n",
       "      <th>sentence-transformers/LaBSE_text_feature_767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.857106</td>\n",
       "      <td>-0.215657</td>\n",
       "      <td>1.067143</td>\n",
       "      <td>0.311904</td>\n",
       "      <td>-0.330101</td>\n",
       "      <td>0.720545</td>\n",
       "      <td>-0.263803</td>\n",
       "      <td>0.03688</td>\n",
       "      <td>-0.350564</td>\n",
       "      <td>-0.579427</td>\n",
       "      <td>...</td>\n",
       "      <td>0.297108</td>\n",
       "      <td>-0.040586</td>\n",
       "      <td>0.602947</td>\n",
       "      <td>-0.2219</td>\n",
       "      <td>1.02662</td>\n",
       "      <td>0.107726</td>\n",
       "      <td>-0.359772</td>\n",
       "      <td>0.015022</td>\n",
       "      <td>-0.514056</td>\n",
       "      <td>-0.497934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence-transformers/LaBSE_text_feature_0  \\\n",
       "0                                    0.857106   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_1  \\\n",
       "0                                   -0.215657   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_2  \\\n",
       "0                                    1.067143   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_3  \\\n",
       "0                                    0.311904   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_4  \\\n",
       "0                                   -0.330101   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_5  \\\n",
       "0                                    0.720545   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_6  \\\n",
       "0                                   -0.263803   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_7  \\\n",
       "0                                     0.03688   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_8  \\\n",
       "0                                   -0.350564   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_9  ...  \\\n",
       "0                                   -0.579427  ...   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_758  \\\n",
       "0                                      0.297108   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_759  \\\n",
       "0                                     -0.040586   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_760  \\\n",
       "0                                      0.602947   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_761  \\\n",
       "0                                       -0.2219   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_762  \\\n",
       "0                                       1.02662   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_763  \\\n",
       "0                                      0.107726   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_764  \\\n",
       "0                                     -0.359772   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_765  \\\n",
       "0                                      0.015022   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_766  \\\n",
       "0                                     -0.514056   \n",
       "\n",
       "   sentence-transformers/LaBSE_text_feature_767  \n",
       "0                                     -0.497934  \n",
       "\n",
       "[1 rows x 768 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_full.iloc[:1, 1850:])\n",
    "display(train_False_True_4_llm_tiny2_512.iloc[:1, 1850:])\n",
    "display(train_False_True_4_llm_tiny2_2048.iloc[:1, 1850:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "RANDOM_STATE = 42\n",
    "cb_init_params_cust = {\n",
    "        'loss_function': 'MultiClass',\n",
    "        \n",
    "        # Ограничим глубину деревьев для ускорения\n",
    "        'depth': 4,\n",
    "        'iterations': 3500,\n",
    "\n",
    "        # Регуляризация и ускорение\n",
    "        'max_bin': 187,\n",
    "        'task_type': 'GPU' if torch.cuda.is_available() else 'CPU',\n",
    "        'thread_count': -1,\n",
    "        'bootstrap_type': 'Bernoulli', \n",
    "            \n",
    "        # Важное!\n",
    "        'random_seed': RANDOM_STATE,\n",
    "        'auto_class_weights': 'SqrtBalanced',\n",
    "        'early_stopping_rounds': 30\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(algorithm,\n",
    "                X,\n",
    "                y,\n",
    "                early_stopping_rounds,\n",
    "                init_params=None,\n",
    "                cat_features=None,\n",
    "                text_features=None,\n",
    "                random_seed=2024\n",
    "    ):\n",
    "    scores = []\n",
    "    models = []\n",
    "\n",
    "    kf = KFold(n_splits=3, shuffle=True, random_state=random_seed)\n",
    "\n",
    "    print(f\"========= TRAINING {algorithm.__name__} =========\")\n",
    "\n",
    "    for num_fold, (train_index, val_index) in enumerate(kf.split(X)):\n",
    "        X_train, X_eval = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train, y_eval = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "        if init_params is not None:\n",
    "            model = algorithm(**init_params)\n",
    "        else:\n",
    "            model = algorithm()\n",
    "\n",
    "        if 'CatBoost' in algorithm.__name__:\n",
    "            # Специальный класс для ускорения обучения \n",
    "            train_dataset = Pool(data=X_train, label=y_train, cat_features=cat_features, text_features=text_features)\n",
    "            eval_dataset  = Pool(data=X_eval, label=y_eval, cat_features=cat_features, text_features=text_features)\n",
    "\n",
    "            model.fit(train_dataset,\n",
    "                      eval_set=eval_dataset,\n",
    "                      verbose=0,\n",
    "                      early_stopping_rounds=early_stopping_rounds)\n",
    "\n",
    "        elif 'LGBM' in algorithm.__name__:\n",
    "            # Специальный класс для ускорения обучения \n",
    "            train_dataset = Dataset(X_train, y_train, categorical_feature=cat_features, free_raw_data=False,)\n",
    "            eval_dataset  = Dataset(X_eval, y_eval, categorical_feature=cat_features, free_raw_data=False,)\n",
    "\n",
    "            model = lgb.train(params=init_params,\n",
    "                              train_set=train_dataset,\n",
    "                              valid_sets=(eval_dataset),\n",
    "                              #callbacks=[lgb.log_evaluation(10)],\n",
    "                              #           lgb.early_stopping(stopping_rounds=5)],\n",
    "                              categorical_feature=cat_features,\n",
    "                              #verbose_eval=False                   # в новой версии LightGBM по логи по умолчанию отключены\n",
    "                              )\n",
    "\n",
    "        elif 'XGB' in algorithm.__name__:\n",
    "            # Специальный класс для ускорения обучения\n",
    "            train_dataset = xgb.DMatrix(X_train, label=y_train, nthread=-1, enable_categorical=True,)\n",
    "            eval_dataset  = xgb.DMatrix(X_eval,  label=y_eval,  nthread=-1, enable_categorical=True,)\n",
    "\n",
    "            model = xgb.train(params=init_params,\n",
    "                              dtrain=train_dataset,\n",
    "                              evals=[(train_dataset, 'dtrain'), (eval_dataset, 'dtest')],\n",
    "                              verbose_eval=False,\n",
    "                              early_stopping_rounds=early_stopping_rounds)\n",
    "\n",
    "            X_eval = eval_dataset\n",
    "\n",
    "        # Предсказание на X_eval и расчет RMSE\n",
    "        y_pred = model.predict(X_eval)\n",
    "        score = balanced_accuracy_score(y_eval, y_pred)\n",
    "\n",
    "        models.append(model)\n",
    "        scores.append(score)\n",
    "\n",
    "        print(f'FOLD {num_fold}: SCORE {score}')\n",
    "\n",
    "    mean_kfold_score = np.mean(scores, dtype=\"float16\") - np.std(scores, dtype=\"float16\")\n",
    "    print(\"\\nMEAN BALANCED ACCURACY SCORE\", mean_kfold_score)\n",
    "\n",
    "    # Модель с наименьшим значением скора\n",
    "    best_model = models[scores.index(min(scores))]\n",
    "\n",
    "    return mean_kfold_score, best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_full = pd.read_csv('https://www.dropbox.com/scl/fi/9hb4r3uce0mqz8fkpja17/text_classification_train.csv?rlkey=w42y98wa401gelzou08pp582k&dl=1')\n",
    "test_full = pd.read_csv('https://www.dropbox.com/scl/fi/7z7rsy14amjeugf166i1t/text_classification_test.csv?rlkey=z53jgwhijd6bpvk7n8n2munwb&dl=1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['category', 'text']].to_csv('../data/text_classification_train.csv', index=False)\n",
    "test[['text']].to_csv('../data/text_classification_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sberbank-ai/ruBert-base\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "281560c26c23404c937d828886efeb60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cointegrated/rubert-tiny2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ee05043aec043079326283b45f6aaf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepPavlov/rubert-base-cased-conversational\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased-conversational were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03a6c3cc29c440888b645bf4753e643c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence-transformers/LaBSE\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbc99a6588fe425e9ad107c7604c0839",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sberbank-ai/ruBert-base\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e8f7ea0face42378374bf90cf0c71c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cointegrated/rubert-tiny2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eafdca18c75e494c85bc3cd2eefee299",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepPavlov/rubert-base-cased-conversational\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased-conversational were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "505f16b4f2b24a8084a5fe5a7a15fe77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence-transformers/LaBSE\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e1801fa86f943a0abb9047dd53aaab9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= TRAINING CatBoostClassifier =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: less than 75% gpu memory available for training. Free: 15746 Total: 24575.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0: SCORE 0.7102006936876464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: less than 75% gpu memory available for training. Free: 15746 Total: 24575.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1: SCORE 0.7059972862978534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: less than 75% gpu memory available for training. Free: 15746 Total: 24575.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 2: SCORE 0.7068371155758295\n",
      "\n",
      "MEAN BALANCED ACCURACY SCORE 0.7056\n"
     ]
    }
   ],
   "source": [
    "# Полный список поддерживаемых моделей можно найти на https://huggingface.co/models\n",
    "\n",
    "models = [\n",
    "          ('sberbank-ai/ruBert-base', 512),\n",
    "          ('cointegrated/rubert-tiny2', 2048),\n",
    "          ('DeepPavlov/rubert-base-cased-conversational', 512),\n",
    "          ('sentence-transformers/LaBSE', 512),\n",
    "         # ('cointegrated/LaBSE-en-ru', 512),\n",
    "          # ('sberbank-ai/ruRoberta-large', 512),\n",
    "           #('sberbank-ai/sbert_large_nlu_ru', 512),\n",
    "           #('sberbank-ai/sbert_large_mt_nlu_ru', 512),\n",
    "           #('sberbank-ai/ruBert-large', 512),\n",
    "          \n",
    "\n",
    "          \n",
    "           #('microsoft/mdeberta-v3-base', 512),\n",
    "           #('vicgalle/xlm-roberta-large-xnli-anli', 512),\n",
    "           #('MoritzLaurer/mDeBERTa-v3-base-mnli-xnli', 512),\n",
    "           #('facebook/bart-large-mnli', 1024)\n",
    "]\n",
    "\n",
    "train = pd.read_csv('../data/text_classification_train.csv')\n",
    "test = pd.read_csv('../data/text_classification_test.csv')\n",
    "    \n",
    "    \n",
    "    \n",
    "text_embeddings = TextEmbeddings(False, True)\n",
    "train = text_embeddings.add_many_embeddings(train, 'text', models)\n",
    "test = text_embeddings.add_many_embeddings(test, 'text', models)\n",
    "\n",
    "train.to_csv('train_False_True_4_llm_tiny2_2048.csv', index=False)\n",
    "test.to_csv('test_False_True_4_llm_tiny2_2048.csv', index=False)\n",
    "\n",
    "cb_score, cb_model = train_model(\n",
    "        algorithm=CatBoostClassifier,\n",
    "        X=train.drop(columns=['category', 'text']), y=train['category'],\n",
    "        init_params=cb_init_params_cust,\n",
    "        early_stopping_rounds=30,\n",
    "        #text_features=['text'],\n",
    "        random_seed=RANDOM_STATE\n",
    "        )\n",
    "\n",
    "pd.DataFrame(cb_model.predict(test.drop(columns='text')), columns=['category']).to_csv('../subs/cb_model_False_True_4_llm_tiny2_2048.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Часть 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install optuna optuna-integration catboost -q\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold, train_test_split, cross_val_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "import optuna\n",
    "import torch\n",
    "import seaborn as sns\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('https://www.dropbox.com/scl/fi/9hb4r3uce0mqz8fkpja17/text_classification_train.csv?rlkey=w42y98wa401gelzou08pp582k&dl=1')\n",
    "test = pd.read_csv('https://www.dropbox.com/scl/fi/7z7rsy14amjeugf166i1t/text_classification_test.csv?rlkey=z53jgwhijd6bpvk7n8n2munwb&dl=1')\n",
    "\n",
    "print(train.shape, test.shape)\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вспомогательные функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(algorithm,\n",
    "                X,\n",
    "                y,\n",
    "                early_stopping_rounds,\n",
    "                init_params=None,\n",
    "                cat_features=None,\n",
    "                text_features=None,\n",
    "                random_seed=2024\n",
    "    ):\n",
    "    scores = []\n",
    "    models = []\n",
    "\n",
    "    kf = KFold(n_splits=3, shuffle=True, random_state=random_seed)\n",
    "\n",
    "    print(f\"========= TRAINING {algorithm.__name__} =========\")\n",
    "\n",
    "    for num_fold, (train_index, val_index) in enumerate(kf.split(X)):\n",
    "        X_train, X_eval = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train, y_eval = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "        if init_params is not None:\n",
    "            model = algorithm(**init_params)\n",
    "        else:\n",
    "            model = algorithm()\n",
    "\n",
    "        if 'CatBoost' in algorithm.__name__:\n",
    "            # Специальный класс для ускорения обучения \n",
    "            train_dataset = Pool(data=X_train, label=y_train, cat_features=cat_features, text_features=text_features)\n",
    "            eval_dataset  = Pool(data=X_eval, label=y_eval, cat_features=cat_features, text_features=text_features)\n",
    "\n",
    "            model.fit(train_dataset,\n",
    "                      eval_set=eval_dataset,\n",
    "                      verbose=0,\n",
    "                      early_stopping_rounds=early_stopping_rounds)\n",
    "\n",
    "        elif 'LGBM' in algorithm.__name__:\n",
    "            # Специальный класс для ускорения обучения \n",
    "            train_dataset = Dataset(X_train, y_train, categorical_feature=cat_features, free_raw_data=False,)\n",
    "            eval_dataset  = Dataset(X_eval, y_eval, categorical_feature=cat_features, free_raw_data=False,)\n",
    "\n",
    "            model = lgb.train(params=init_params,\n",
    "                              train_set=train_dataset,\n",
    "                              valid_sets=(eval_dataset),\n",
    "                              #callbacks=[lgb.log_evaluation(10)],\n",
    "                              #           lgb.early_stopping(stopping_rounds=5)],\n",
    "                              categorical_feature=cat_features,\n",
    "                              #verbose_eval=False                   # в новой версии LightGBM по логи по умолчанию отключены\n",
    "                              )\n",
    "\n",
    "        elif 'XGB' in algorithm.__name__:\n",
    "            # Специальный класс для ускорения обучения\n",
    "            train_dataset = xgb.DMatrix(X_train, label=y_train, nthread=-1, enable_categorical=True,)\n",
    "            eval_dataset  = xgb.DMatrix(X_eval,  label=y_eval,  nthread=-1, enable_categorical=True,)\n",
    "\n",
    "            model = xgb.train(params=init_params,\n",
    "                              dtrain=train_dataset,\n",
    "                              evals=[(train_dataset, 'dtrain'), (eval_dataset, 'dtest')],\n",
    "                              verbose_eval=False,\n",
    "                              early_stopping_rounds=early_stopping_rounds)\n",
    "\n",
    "            X_eval = eval_dataset\n",
    "\n",
    "        # Предсказание на X_eval и расчет RMSE\n",
    "        y_pred = model.predict(X_eval)\n",
    "        score = balanced_accuracy_score(y_eval, y_pred)\n",
    "\n",
    "        models.append(model)\n",
    "        scores.append(score)\n",
    "\n",
    "        print(f'FOLD {num_fold}: SCORE {score}')\n",
    "\n",
    "    mean_kfold_score = np.mean(scores, dtype=\"float16\") - np.std(scores, dtype=\"float16\")\n",
    "    print(\"\\nMEAN BALANCED ACCURACY SCORE\", mean_kfold_score)\n",
    "\n",
    "    # Модель с наименьшим значением скора\n",
    "    best_model = models[scores.index(min(scores))]\n",
    "\n",
    "    return mean_kfold_score, best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение CatBoost модели с текстовыми признаками и кастомными параметрами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_init_params_cust = {\n",
    "        'loss_function': 'MultiClass',\n",
    "        \n",
    "        # Ограничим глубину деревьев для ускорения\n",
    "        'depth': 4,\n",
    "        'iterations': 3500,\n",
    "\n",
    "        # Регуляризация и ускорение\n",
    "        'max_bin': 187,\n",
    "        'task_type': 'GPU' if torch.cuda.is_available() else 'CPU',\n",
    "        'thread_count': -1,\n",
    "        'bootstrap_type': 'Bernoulli', \n",
    "            \n",
    "        # Важное!\n",
    "        'random_seed': RANDOM_STATE,\n",
    "        'auto_class_weights': 'SqrtBalanced',\n",
    "        'early_stopping_rounds': 30\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_score, cb_model = train_model(\n",
    "    algorithm=CatBoostClassifier,\n",
    "    X=train.drop(columns=['category']), y=train['category'],\n",
    "    init_params=cb_init_params_cust,\n",
    "    early_stopping_rounds=30,\n",
    "    text_features=['text'],\n",
    "    random_seed=RANDOM_STATE\n",
    ")\n",
    "\n",
    "pd.DataFrame(cb_model.predict(test), columns=['category']).to_csv('../subs/cb_model_preds.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy на лидерборде 0.7568"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection (Shap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'shap_result.json' in os.listdir('../src'):\n",
    "    # загрузка параметров из файла\n",
    "    with open('../src/shap_result.json', 'r') as read_file:\n",
    "        shap_result = json.load(read_file)\n",
    "    row = shap_result['shap_result']\n",
    "\n",
    "else:\n",
    "    X_train, X_eval, y_train, y_eval = train_test_split(train.drop(columns=['category']), train['category'], test_size=0.2, random_state=42)\n",
    "\n",
    "    model = CatBoostClassifier(**cb_init_params_cust)\n",
    "\n",
    "    train_dataset = Pool(data=X_train, label=y_train, text_features=['text'])\n",
    "    eval_dataset  = Pool(data=X_eval, label=y_eval, text_features=['text'])\n",
    "\n",
    "    model.fit(train_dataset, \n",
    "            eval_set=eval_dataset,\n",
    "            verbose=0, plot=False,\n",
    "            early_stopping_rounds=30)\n",
    "\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "\n",
    "    cat_features = None\n",
    "\n",
    "    #train_dataset = Pool(data=X_train, label=y_train, cat_features=cat_features, text_features=text_cols)\n",
    "    shap_values = explainer.shap_values(train_dataset)\n",
    "\n",
    "    row = [shap_values[:, feature_ind, :] for feature_ind in range(shap_values.shape[1])]\n",
    "    row = [np.abs(i).mean(0).mean() for i in row]\n",
    "\n",
    "    shap_result={\n",
    "        'shap_result': row\n",
    "        }\n",
    "\n",
    "    # сохранение результатов в файл\n",
    "    with open('../src/shap_result.json', 'w') as f:\n",
    "        json.dump(shap_result, f)\n",
    "\n",
    "top_shap_idx = sorted(range(len(row)), key=lambda k: row[k], reverse=True)\n",
    "\n",
    "df_plot = []\n",
    "cum_shap_value = 0\n",
    "for shap_value in sorted(row, reverse=True):\n",
    "    cum_shap_value += shap_value\n",
    "    df_plot.append(cum_shap_value)\n",
    "df_plot = pd.DataFrame(df_plot, columns=['shap_value'])\n",
    "\n",
    "sns.relplot(\n",
    "    data=df_plot,\n",
    "    kind=\"line\",\n",
    "    height=4, \n",
    "    aspect=2,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подбор количества фичей\n",
    "for num_col in range(200, 900, 50):\n",
    "    X_train, X_eval, y_train, y_eval = train_test_split(train[train.drop(columns=['category']).columns[top_shap_idx[:num_col]]], train['category'], test_size=0.2, random_state=42)\n",
    "    train_dataset = Pool(data=X_train, label=y_train, text_features=['text'])\n",
    "    eval_dataset  = Pool(data=X_eval, label=y_eval, text_features=['text'])\n",
    "\n",
    "    cb_model = CatBoostClassifier(**cb_init_params_cust)\n",
    "    cb_model.fit(train_dataset, \n",
    "            eval_set=eval_dataset,\n",
    "            verbose=0, plot=False, \n",
    "            early_stopping_rounds=30)\n",
    "\n",
    "    y_pred = cb_model.predict(X_eval)\n",
    "    score = balanced_accuracy_score(y_eval, y_pred)\n",
    "    print(num_col, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_score, cb_model = train_model(\n",
    "    algorithm=CatBoostClassifier,\n",
    "    X=train[train.drop(columns=['category']).columns[top_shap_idx[:500]]], y=train['category'],\n",
    "    init_params=cb_init_params_cust,\n",
    "    early_stopping_rounds=30,\n",
    "    text_features=['text'],\n",
    "    random_seed=RANDOM_STATE\n",
    ")\n",
    "\n",
    "pd.DataFrame(cb_model.predict(test[test.columns[top_shap_idx[:500]]]),\n",
    "             columns=['category']).to_csv('../subs/cb_model_preds.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy на лидерборде 0.7604"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF + классификатор"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X_TFIDF = vectorizer.fit_transform(train['text'])\n",
    "X_TFIDF_train, X_TFIDF_eval, y_TFIDF_train, y_TFIDF_eval = train_test_split(X_TFIDF, train['category'], test_size=0.2, random_state=42)\n",
    "X_TFIDF_test  = vectorizer.transform(test['text'])\n",
    "\n",
    "print(X_TFIDF_train.shape)\n",
    "print(X_TFIDF_eval.shape)\n",
    "print(X_TFIDF_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обечение с валидацией\n",
    "logreg = LogisticRegression(random_state=RANDOM_STATE)\n",
    "logreg.fit(X_TFIDF_train, y_TFIDF_train)\n",
    "print(balanced_accuracy_score(y_TFIDF_eval, logreg.predict(X_TFIDF_eval)))\n",
    "\n",
    "# Обучение на всех данных\n",
    "logreg.fit(X_TFIDF, train['category'])\n",
    "pd.DataFrame(logreg.predict(X_TFIDF_test), columns=['category']).to_csv('../subs/tfids_logreg.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy на лидерборде 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подбор гиперпараметров\n",
    "def objective_svc(trial):\n",
    "\n",
    "    C = trial.suggest_float(\"C\",0.1,1000)\n",
    "    gamma = trial.suggest_float(\"gamma\",0.0001,1)\n",
    "    kernel = trial.suggest_categorical(\"kernel\",['rbf','poly']) \n",
    "    model = SVC(\n",
    "        C=C,\n",
    "        gamma=gamma,\n",
    "        kernel=kernel,\n",
    "        random_state=RANDOM_STATE\n",
    "    )  \n",
    "    score = cross_val_score(model, X_TFIDF_train, y, cv=3)\n",
    "    accuracy = score.mean()\n",
    "    return accuracy\n",
    "\n",
    "if 'params_svc.json' in os.listdir('../src'):\n",
    "    # загрузка параметров из файла\n",
    "    with open('../src/params_svc.json', 'r') as read_file:\n",
    "        params_svc = json.load(read_file)\n",
    "        \n",
    "else:\n",
    "    X_TFIDF_train = vectorizer.fit_transform(train['text'])\n",
    "    \n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective_svc,\n",
    "                n_trials=100,\n",
    "                n_jobs = -1)\n",
    "\n",
    "    print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "    print(\"  Value: {}\".format(trial.value))\n",
    "    params_svc = trial.params\n",
    "\n",
    "    # сохранение результатов в файл\n",
    "    with open('../src/params_svc.json', 'w') as f:\n",
    "        json.dump(params_svc, f)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in params_svc.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обечение с валидацией\n",
    "#svc_clf = SVC(C=2.5, gamma=0.7, random_state=RANDOM_STATE)\n",
    "svc_clf = SVC(**params_svc)\n",
    "svc_clf.fit(X_TFIDF_train, y_TFIDF_train)\n",
    "print(balanced_accuracy_score(y_TFIDF_eval, svc_clf.predict(X_TFIDF_eval)))\n",
    "\n",
    "# Обучение на всех данных\n",
    "svc_clf.fit(X_TFIDF, train['category'])\n",
    "pd.DataFrame(svc_clf.predict(X_TFIDF_test), columns=['category']).to_csv('../subs/tfids_svc.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy на лидерборде  0.7716"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обечение с валидацией\n",
    "linear_svc = LinearSVC(tol=0.01, dual=True, C=0.6, random_state=RANDOM_STATE)\n",
    "linear_svc.fit(X_TFIDF_train, y_TFIDF_train)\n",
    "print(balanced_accuracy_score(y_TFIDF_eval, linear_svc.predict(X_TFIDF_eval)))\n",
    "\n",
    "# Обучение на всех данных\n",
    "linear_svc.fit(X_TFIDF, train['category'])\n",
    "pd.DataFrame(linear_svc.predict(X_TFIDF_test), columns=['category']).to_csv('../subs/tfids_lin_svc.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy на лидерборде 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обечение с валидацией\n",
    "et_clf = ExtraTreesClassifier(n_estimators = 6_000, max_depth = 8, min_samples_leaf = 2, bootstrap = True,\n",
    "                              class_weight = 'balanced',random_state = RANDOM_STATE, verbose=False, n_jobs=-1)\n",
    "et_clf.fit(X_TFIDF_train, y_TFIDF_train)\n",
    "print(balanced_accuracy_score(y_TFIDF_eval, et_clf.predict(X_TFIDF_eval)))\n",
    "\n",
    "# Обучение на всех данных\n",
    "et_clf.fit(X_TFIDF, train['category'])\n",
    "pd.DataFrame(et_clf.predict(X_TFIDF_test), columns=['category']).to_csv('../subs/tfids_et.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy на лидерборде 0.6836 (можно подбором гиперпараметров увеличить до 0.7432, но метрика при стекинге падает)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обечение с валидацией\n",
    "rf = RandomForestClassifier(n_estimators=10_000, max_depth=200, n_jobs=-1, random_state=RANDOM_STATE)\n",
    "rf.fit(X_TFIDF_train, y_TFIDF_train)\n",
    "print(balanced_accuracy_score(y_TFIDF_eval, rf.predict(X_TFIDF_eval)))\n",
    "\n",
    "# Обучение на всех данных\n",
    "rf.fit(X_TFIDF, train['category'])\n",
    "pd.DataFrame(rf.predict(X_TFIDF_test), columns=['category']).to_csv('../subs/tfids_rf.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy на лидерборде 0.7068"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Стекинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stacker:\n",
    "    def __init__(self, base_models, meta_model, preprocessing=None, metafeatures_mode=None):\n",
    "        \"\"\"\n",
    "        base_models - список базовых моделей, которые нужно обучать на изначальных данных\n",
    "        meta_model - мета модель, которая обучается на предсказаниях базовых моделей\n",
    "        metafeatures_mode - режим формирования фичей ('pred' - предикт, 'proba' - вероятность, 'log_proba' - логарифм вероятности\n",
    "        preprocessing - список словарей операций над датасетом:\n",
    "            col_select - выбор столбцов\n",
    "            col_drop - удаление столбцов\n",
    "            tfidf - преобразование tfidf по указанному столбцу\n",
    "            text_features - список текстовых сболбцов для подачи в CatBoost\n",
    "        \"\"\"\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.preprocessing = preprocessing\n",
    "        self.metafeatures_mode = metafeatures_mode if metafeatures_mode else [['pred'] for m in base_models]\n",
    "        self.vectorizer = None\n",
    "        self.additional_meta_features = False # дополнительные метафичи (разность, деление существующих)\n",
    "        self.meta_cat_features = None\n",
    "        self.meta_le = {}\n",
    "\n",
    "    def X_preprocessing(self, X, num_model):\n",
    "        if 'col_drop' in self.preprocessing[num_model]:\n",
    "            X.drop(columns=self.preprocessing[num_model]['col_drop'], inplace=True)\n",
    "        if 'col_select' in self.preprocessing[num_model]:\n",
    "            X = X[self.preprocessing[num_model]['col_select']] \n",
    "        if 'tfidf' in self.preprocessing[num_model]:\n",
    "            X = self.vectorizer.transform(X[self.preprocessing[num_model]['tfidf']])      \n",
    "        return X\n",
    "    \n",
    "    def base_model_one_pred(self, model, mode, X):\n",
    "        if mode == 'pred':\n",
    "            preds = model.predict(X)\n",
    "            preds = preds.reshape(len(preds), 1)\n",
    "        elif mode == 'proba':\n",
    "            if model.__class__.__name__ == 'LinearSVC':\n",
    "                 preds = model._predict_proba_lr(X)\n",
    "            else:\n",
    "                preds = model.predict_proba(X)\n",
    "        elif mode == 'log_proba':\n",
    "            preds = model.predict_log_proba(X)\n",
    "        \n",
    "        # костыль для избавления от -inf в RF\n",
    "        if model.__class__.__name__ == 'RandomForestClassifier':\n",
    "            preds[np.where(preds == float('-inf'))] = -100\n",
    "            preds[np.where(preds == float('inf'))] = 100\n",
    "\n",
    "        return preds\n",
    "    \n",
    "    def base_model_all_preds(self, model, num_model, X):\n",
    "        #preds_all = None\n",
    "        preds_all = np.empty((X.shape[0], 0))\n",
    "        for mode in self.metafeatures_mode[num_model]:\n",
    "            preds = self.base_model_one_pred(model, mode, X)\n",
    "            #preds_all = preds if preds_all is None else np.concatenate([preds_all, preds], axis=1) \n",
    "            preds_all = np.concatenate([preds_all, preds], axis=1)\n",
    "        return preds_all\n",
    "    \n",
    "    def base_model_fit(self, model, num_model, X_train, y_train, X_val=None, y_val=None):\n",
    "                \n",
    "        if model.__class__.__name__ == 'CatBoostClassifier':\n",
    "            #best_iter = 0\n",
    "            text_features = []\n",
    "            if 'text_features' in self.preprocessing[num_model]:            # возможно вынести наверх (в основную функцию)\n",
    "                for i in preprocessing[num_model]['text_features']:\n",
    "                    text_features.append(X_train.columns.get_loc(i))\n",
    "            cat_features = []\n",
    "            for i in range(X_train.shape[1]):\n",
    "                if type(X_train.iloc[0, i]) == str:\n",
    "                    if i not in text_features:\n",
    "                        cat_features.append(i)\n",
    "\n",
    "            if X_val is not None and y_val is not None:\n",
    "                model.fit(X_train, y_train, eval_set=(X_val, y_val), cat_features=cat_features, text_features=text_features,\n",
    "                          verbose=False, early_stopping_rounds=30)\n",
    "                #if model.best_iteration_ > best_iter:\n",
    "                    #best_iter = model.best_iteration_\n",
    "            else:\n",
    "                model.fit(X_train, y_train, cat_features=cat_features, text_features=text_features, verbose=False)\n",
    "        else:\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "    def fit_base(self, X, y, n_fold=5):\n",
    "        # если есть tfidf - обучаем vectorizer\n",
    "        for params in preprocessing:\n",
    "            if 'tfidf' in params.keys():\n",
    "                self.vectorizer = TfidfVectorizer()\n",
    "                self.vectorizer.fit(X[params['tfidf']])\n",
    "                print('Сформирован vectorizer:', self.vectorizer.get_feature_names_out().shape[0], 'токенов.')\n",
    "                break\n",
    "        \n",
    "        folds = KFold(n_splits=n_fold)\n",
    "        final_features = np.empty((len(X), 0))\n",
    "\n",
    "        for num_model, model in enumerate(self.base_models):\n",
    "            \n",
    "            preds_model = None\n",
    "        \n",
    "            for train_indices, val_indices in folds.split(X, y):\n",
    " \n",
    "                X_train, X_val = X.loc[train_indices], X.loc[val_indices]\n",
    "                X_train, X_val = self.X_preprocessing(X_train, num_model), self.X_preprocessing(X_val, num_model)\n",
    "                y_train, y_val = y[train_indices], y[val_indices]        \n",
    "            \n",
    "                self.base_model_fit(model, num_model, X_train, y_train, X_val, y_val)\n",
    "                preds_fold = self.base_model_all_preds(model, num_model, X_val)\n",
    "                preds_model = preds_fold if preds_model is None else np.concatenate([preds_model, preds_fold], axis=0)\n",
    "            \n",
    "            final_features = np.concatenate([final_features, preds_model], axis=1)\n",
    "\n",
    "            self.base_model_fit(model, num_model, self.X_preprocessing(X, num_model), y)\n",
    "            print('Обучена базовая модель №', num_model+1, model.__class__.__name__)\n",
    "            \n",
    "        return final_features\n",
    "    \n",
    "    def add_meta_features(self, X):\n",
    "        \n",
    "        meta_num_features = []\n",
    "        for i in range(X.shape[1]):\n",
    "            if type(X[0][i]) == float:\n",
    "                meta_num_features.append(i)\n",
    "        \n",
    "        new_features = []\n",
    "        for source in meta_num_features:\n",
    "            for destination in meta_num_features:\n",
    "                row = X[:, source] / X[:, destination]\n",
    "                new_features.append(row.reshape(len(row),1))\n",
    "                row = X[:, source] - X[:, destination]\n",
    "                new_features.append(row.reshape(len(row),1))\n",
    "        new_features = np.concatenate(new_features, axis=1)\n",
    "        new_features = np.concatenate([X, new_features], axis=1)\n",
    "\n",
    "        return new_features\n",
    "\n",
    "    def fit_meta(self, meta_features, y):\n",
    "        \n",
    "        self.meta_cat_features = []\n",
    "        for i in range(meta_features.shape[1]):\n",
    "            if type(meta_features[0][i]) == str:\n",
    "                self.meta_cat_features.append(i)\n",
    "        \n",
    "        if self.meta_model.__class__.__name__ == 'CatBoostClassifier':\n",
    "            self.meta_model.fit(pd.DataFrame(meta_features), y, cat_features=self.meta_cat_features, verbose=False)\n",
    "        else:\n",
    "            for col in self.meta_cat_features:\n",
    "                self.meta_le[col] = LabelEncoder()\n",
    "                meta_features[:, col] = self.meta_le[col].fit_transform(meta_features[:, col])\n",
    "\n",
    "            self.meta_model.fit(pd.DataFrame(meta_features), y)\n",
    "        print('cat_features', self.meta_cat_features)\n",
    "        print('Обучена метамодель', self.meta_model.__class__.__name__)\n",
    "        return None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        meta_features = self.fit_base(X, y)\n",
    "        if self.additional_meta_features == True:\n",
    "            meta_features=self.add_meta_features(meta_features)\n",
    "            print('Сформированы дополнительные фичи')\n",
    "        self.fit_meta(meta_features, y)\n",
    "    \n",
    "    def predict(self, X):\n",
    "\n",
    "        final_features = np.empty((len(X), 0))\n",
    "        \n",
    "        for num_model, model in enumerate(self.base_models):\n",
    "            \n",
    "            # X preprocessing\n",
    "            X_test = self.X_preprocessing(X, num_model)\n",
    "            preds_model = self.base_model_all_preds(model, num_model, X_test)\n",
    "            final_features = np.concatenate([final_features, preds_model], axis=1)\n",
    "        \n",
    "        \n",
    "        if self.meta_model.__class__.__name__ == 'CatBoostClassifier':\n",
    "            final_preds = self.meta_model.predict(final_features)\n",
    "        else:\n",
    "            for col in self.meta_cat_features:\n",
    "                final_features[:, col] = self.meta_le[col].transform(final_features[:, col])\n",
    "\n",
    "            final_preds = self.meta_model.predict(final_features)\n",
    "            final_preds = final_preds.reshape(len(final_preds), 1)\n",
    "\n",
    "        return final_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем экземпляр Stacker\n",
    "base_models = [CatBoostClassifier(**cb_init_params_cust),\n",
    "               LogisticRegression(random_state=RANDOM_STATE),\n",
    "               SVC(**params_svc, probability=True, decision_function_shape='ovr', random_state=RANDOM_STATE),\n",
    "               LinearSVC(tol=0.01, dual=True, C=0.6, random_state=RANDOM_STATE),\n",
    "               ExtraTreesClassifier(n_estimators = 6_000, max_depth = 8, min_samples_leaf = 2, bootstrap = True,\n",
    "                                    class_weight = 'balanced',random_state = RANDOM_STATE, verbose=False, n_jobs=-1,),\n",
    "               #RandomForestClassifier(n_estimators = 10_000, max_depth = 200, n_jobs=-1, random_state = RANDOM_STATE)\n",
    "               ]\n",
    "\n",
    "meta_model = LogisticRegression(random_state=RANDOM_STATE)\n",
    "\n",
    "preprocessing = [{'col_select':train.drop(columns=['category']).columns[top_shap_idx[:500]], 'text_features':['text']},\n",
    "                 {'col_select':['text'], 'tfidf':'text'},\n",
    "                 {'col_select':['text'], 'tfidf':'text'},\n",
    "                 {'col_select':['text'], 'tfidf':'text'},\n",
    "                 {'col_select':['text'], 'tfidf':'text'},\n",
    "                 #{'col_select':['text'], 'tfidf':'text'}\n",
    "                 ]\n",
    "\n",
    "metafeatures_mode = [['pred', 'proba', 'log_proba'],\n",
    "                     ['pred', 'proba', 'log_proba'],\n",
    "                     ['pred', 'proba', 'log_proba'],\n",
    "                     ['pred', 'proba'],\n",
    "                     ['pred', 'proba', 'log_proba'],\n",
    "                     #['pred', 'proba', 'log_proba']\n",
    "                     ]\n",
    "\n",
    "stacker = Stacker(base_models, meta_model, preprocessing, metafeatures_mode)\n",
    "stacker.fit(train.drop(columns=['category']), train['category'])\n",
    "res = stacker.predict(test)\n",
    "pd.DataFrame(res, columns=['category']).to_csv('../subs/tfids_stacking.csv', index=False)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
